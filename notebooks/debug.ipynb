{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "L = 5\n",
    "N = 1000\n",
    "C = 10\n",
    "J_D = 0.2\n",
    "LAMBDA_LEFT = [0, 2.0, 2.0, 2.0, 2.0, 1.0]\n",
    "LAMBDA_RIGHT = [4.0, 4.0, 4.0, 4.0, 1.0, 4.0]\n",
    "DEVICE = \"cpu\"\n",
    "SEED = 1232\n",
    "lr = torch.tensor([0.1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01])\n",
    "threshold = torch.tensor([2.5, 2.5, 2.5, 2.5, 2.5, 2.5])\n",
    "weight_decay = torch.tensor([0.001, 0.001, 0.001, 0.001, 0.001, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.batch_me_if_u_can import BatchMeIfUCan\n",
    "from src.handler import Handler\n",
    "\n",
    "new = BatchMeIfUCan(\n",
    "    num_layers=L,\n",
    "    N=N,\n",
    "    C=C,\n",
    "    J_D=J_D,\n",
    "    lambda_left=LAMBDA_LEFT,\n",
    "    lambda_right=LAMBDA_RIGHT,\n",
    "    device=DEVICE,\n",
    "    seed=SEED,\n",
    "    lr=lr,\n",
    "    threshold=threshold,\n",
    "    weight_decay=weight_decay,\n",
    ")\n",
    "handler = Handler(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classifier import Classifier\n",
    "\n",
    "old = Classifier(\n",
    "    num_layers=L,\n",
    "    N=N,\n",
    "    C=C,\n",
    "    J_D=J_D,\n",
    "    lambda_left=LAMBDA_LEFT,\n",
    "    lambda_right=LAMBDA_RIGHT,\n",
    "    device=DEVICE,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import prepare_mnist\n",
    "\n",
    "P = 10\n",
    "P_eval = 10\n",
    "binarize = True\n",
    "\n",
    "train_inputs, train_targets, eval_inputs, eval_targets, projection_matrix = (\n",
    "    prepare_mnist(\n",
    "        P * C,\n",
    "        P_eval * C,\n",
    "        N,\n",
    "        binarize,\n",
    "        SEED,\n",
    "        shuffle=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  ...,  True,  True,  True],\n",
       "        [ True, False,  True,  ...,  True,  True,  True],\n",
       "        [ True,  True, False,  ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True,  ..., False,  True,  True],\n",
       "        [ True,  True,  True,  ...,  True, False,  True],\n",
       "        [ True,  True,  True,  ...,  True,  True, False]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 16\n",
    "x = train_inputs[:B]\n",
    "y = train_targets[:B]\n",
    "\n",
    "non_diagonal_mask = torch.ones((N, N), dtype=torch.bool)\n",
    "non_diagonal_mask.fill_diagonal_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_coup = new.couplings.clone()\n",
    "\n",
    "# for idx in range(new.L):\n",
    "#     new.couplings[idx, :, N : 2 * N] = old.couplings[idx, :, :].clone()\n",
    "#     new.couplings[idx, :, :N][non_diagonal_mask] = 0\n",
    "#     if idx != new.L - 1:\n",
    "#         new.couplings[idx, :, 2 * N : 3 * N][non_diagonal_mask] = 0\n",
    "new.couplings[-2, :, 2 * N : 2 * N + C] = old.W_back.T.clone()\n",
    "new.couplings[-1, :C, :N] = old.W_forth.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.692062497138977\n",
      "0.4657750129699707\n",
      "0.3788124918937683\n",
      "0.3241249918937683\n",
      "0.3245750069618225\n",
      "0.3207874894142151\n",
      "0.303849995136261\n",
      "0.2727625072002411\n",
      "0.28404998779296875\n",
      "0.2829124927520752\n",
      "0.2865374982357025\n",
      "0.29413750767707825\n",
      "0.2879124879837036\n",
      "0.2770499885082245\n",
      "0.24018749594688416\n",
      "0.26365000009536743\n",
      "0.26637500524520874\n",
      "0.2770000100135803\n",
      "0.2695874869823456\n",
      "0.2530750036239624\n",
      "0.27344998717308044\n",
      "0.2442374974489212\n",
      "0.24742500483989716\n",
      "0.24501250684261322\n",
      "0.23623749613761902\n",
      "0.23742499947547913\n",
      "0.23999999463558197\n",
      "0.23395000398159027\n",
      "0.22152499854564667\n",
      "0.21359999477863312\n",
      "0.21236249804496765\n",
      "0.22027499973773956\n",
      "0.22163750231266022\n",
      "0.22644999623298645\n",
      "0.23485000431537628\n",
      "0.1992875039577484\n",
      "0.19876250624656677\n",
      "0.19853749871253967\n",
      "0.19636249542236328\n",
      "0.18952499330043793\n",
      "0.2027125060558319\n",
      "0.17970000207424164\n",
      "0.17361250519752502\n",
      "0.17560000717639923\n",
      "0.17333750426769257\n",
      "0.17499999701976776\n",
      "0.1833374947309494\n",
      "0.16967499256134033\n",
      "0.15809999406337738\n",
      "0.14955000579357147\n",
      "0.14436249434947968\n",
      "0.14791250228881836\n",
      "0.15563750267028809\n",
      "0.16068750619888306\n",
      "0.15393750369548798\n",
      "0.16259999573230743\n"
     ]
    }
   ],
   "source": [
    "epochs = 8\n",
    "new_train_acc_history, new_eval_acc_history, new_representations = handler.train_loop(\n",
    "    epochs,\n",
    "    train_inputs,\n",
    "    train_targets,\n",
    "    5,\n",
    "    B,\n",
    "    1,\n",
    "    eval_inputs,\n",
    "    eval_targets,\n",
    ")\n",
    "old_train_acc_history, old_eval_acc_history, old_representations = old.train_loop(\n",
    "    epochs,\n",
    "    train_inputs,\n",
    "    train_targets,\n",
    "    5,\n",
    "    lr,\n",
    "    threshold,\n",
    "    weight_decay,\n",
    "    B,\n",
    "    1,\n",
    "    eval_inputs,\n",
    "    eval_targets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.23000000417232513,\n",
       "  0.3700000047683716,\n",
       "  0.5,\n",
       "  0.5299999713897705,\n",
       "  0.6700000166893005,\n",
       "  0.6299999952316284,\n",
       "  0.7200000286102295,\n",
       "  0.8100000023841858],\n",
       " [0.23999999463558197,\n",
       "  0.36000001430511475,\n",
       "  0.5600000023841858,\n",
       "  0.6100000143051147,\n",
       "  0.7400000095367432,\n",
       "  0.7400000095367432,\n",
       "  0.8100000023841858,\n",
       "  0.8199999928474426])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_acc_history, old_train_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_equality_couplings(new, old):\n",
    "    for idx in range(new.L):\n",
    "        assert torch.allclose(\n",
    "            new.internal_couplings[idx],\n",
    "            old.couplings[idx, :, :],\n",
    "            atol=1e-5,\n",
    "        )\n",
    "    assert torch.allclose(\n",
    "        new.W_back,\n",
    "        old.W_back.T,\n",
    "        atol=1e-5,\n",
    "    )\n",
    "    assert torch.allclose(\n",
    "        new.W_forth,\n",
    "        old.W_forth,\n",
    "        atol=1e-5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x111403f90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old.generator.manual_seed(0)\n",
    "new.generator.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6969500184059143\n"
     ]
    }
   ],
   "source": [
    "sweeps_old, updates_old = old.train_step(x, y, 5, lr, threshold, weight_decay)\n",
    "sweeps_new = new.train_step(x, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_logits, _, _ = old.inference(x, 5)\n",
    "new_logits, _, _ = new.inference(x, 5)\n",
    "torch.allclose(old_logits, new_logits, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44362500309944153\n",
      "0.382099986076355\n",
      "0.3532249927520752\n",
      "0.32231250405311584\n",
      "0.3210124969482422\n",
      "0.3241625130176544\n",
      "0.31095001101493835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([5, 5, 5, 5, 5, 5, 5],\n",
       " [0.44362500309944153,\n",
       "  0.382099986076355,\n",
       "  0.3532249927520752,\n",
       "  0.32231250405311584,\n",
       "  0.3210124969482422,\n",
       "  0.3241625130176544,\n",
       "  0.31095001101493835])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler.train_epoch(\n",
    "    train_inputs,\n",
    "    train_targets,\n",
    "    5,\n",
    "    B,\n",
    ")\n",
    "old.train_epoch(\n",
    "    train_inputs,\n",
    "    train_targets,\n",
    "    5,\n",
    "    lr,\n",
    "    threshold,\n",
    "    weight_decay,\n",
    "    B,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcheck_equality_couplings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mcheck_equality_couplings\u001b[39m\u001b[34m(new, old)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_equality_couplings\u001b[39m(new, old):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(new.L):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m torch.allclose(\n\u001b[32m      4\u001b[39m             new.internal_couplings[idx],\n\u001b[32m      5\u001b[39m             old.couplings[idx, :, :],\n\u001b[32m      6\u001b[39m             atol=\u001b[32m1e-5\u001b[39m,\n\u001b[32m      7\u001b[39m         )\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m torch.allclose(\n\u001b[32m      9\u001b[39m         new.W_back,\n\u001b[32m     10\u001b[39m         old.W_back.T,\n\u001b[32m     11\u001b[39m         atol=\u001b[32m1e-5\u001b[39m,\n\u001b[32m     12\u001b[39m     )\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m torch.allclose(\n\u001b[32m     14\u001b[39m         new.W_forth,\n\u001b[32m     15\u001b[39m         old.W_forth,\n\u001b[32m     16\u001b[39m         atol=\u001b[32m1e-5\u001b[39m,\n\u001b[32m     17\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "check_equality_couplings(new, old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcheck_equality_couplings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mcheck_equality_couplings\u001b[39m\u001b[34m(new, old)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_equality_couplings\u001b[39m(new, old):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(new.L):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m torch.allclose(\n\u001b[32m      4\u001b[39m             new.internal_couplings[idx],\n\u001b[32m      5\u001b[39m             old.couplings[idx, :, :],\n\u001b[32m      6\u001b[39m             atol=\u001b[32m1e-5\u001b[39m,\n\u001b[32m      7\u001b[39m         )\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m torch.allclose(\n\u001b[32m      9\u001b[39m         new.W_back,\n\u001b[32m     10\u001b[39m         old.W_back.T,\n\u001b[32m     11\u001b[39m         atol=\u001b[32m1e-5\u001b[39m,\n\u001b[32m     12\u001b[39m     )\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m torch.allclose(\n\u001b[32m     14\u001b[39m         new.W_forth,\n\u001b[32m     15\u001b[39m         old.W_forth,\n\u001b[32m     16\u001b[39m         atol=\u001b[32m1e-5\u001b[39m,\n\u001b[32m     17\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "check_equality_couplings(new, old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.11999999731779099, 0.15000000596046448, 0.20999999344348907],\n",
       " [0.23999999463558197, 0.36000001430511475, 0.5600000023841858])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_acc_history, old_train_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "B = 2\n",
    "i = np.random.randint(0, len(train_inputs) - B)\n",
    "x = train_inputs[i : i + B]\n",
    "y = train_targets[i : i + B]\n",
    "new_state = new.initialize_state(B, x, y)\n",
    "old_state, old_readout = old.initialize_neurons_state(B, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set couplings and states to be equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state[:, 1:-2, :] = old_state.permute(1, 0, 2)\n",
    "new_state[:, -2, :C] = old_readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_diagonal_mask = torch.ones((N, N), dtype=torch.bool)\n",
    "non_diagonal_mask.fill_diagonal_(False)\n",
    "\n",
    "for idx in range(new.L):\n",
    "    new.couplings[idx, :, N : 2 * N] = old.couplings[idx, :, :]\n",
    "    new.couplings[idx, :, :N][non_diagonal_mask] = 0\n",
    "    if idx != new.L - 1:\n",
    "        new.couplings[idx, :, 2 * N : 3 * N][non_diagonal_mask] = 0\n",
    "new.couplings[-2, :, 2 * N : 2 * N + C] = old.W_back.T\n",
    "new.couplings[-1, :C, :N] = old.W_forth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_new = new.fields(new_state, ignore_right=0)\n",
    "field_old, readout_field_old = old.local_field(\n",
    "    old_state, old_readout, ignore_right=False, x=x, y=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0026])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "different_mask = ~torch.isclose(field_new[0, :-1], field_old[:, 0])\n",
    "field_new[0, :-1][different_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0026])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_old[:, 0][different_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.2000, -4.4000, -3.8000, -5.0000, -2.4000, -5.0000, -4.2000, -3.6000,\n",
       "          3.2000, -3.4000],\n",
       "        [-4.0000,  1.2000, -2.6000, -3.8000, -4.0000, -4.2000, -5.4000, -3.2000,\n",
       "         -4.0000, -5.8000]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_new[:, -1, :C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.2000, -4.4000, -3.8000, -5.0000, -2.4000, -5.0000, -4.2000, -3.6000,\n",
       "          3.2000, -3.4000],\n",
       "        [-4.0000,  1.2000, -2.6000, -3.8000, -4.0000, -4.2000, -5.4000, -3.2000,\n",
       "         -4.0000, -5.8000]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readout_field_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(old.W_forth == new.couplings[-1, :C, :N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1., -1., -1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,\n",
       "         -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,\n",
       "          1., -1., -1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,\n",
       "         -1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,\n",
       "         -1., -1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "         -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,\n",
       "          1.,  1.],\n",
       "        [ 1., -1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,\n",
       "          1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,\n",
       "          1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
       "          1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,\n",
       "         -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,\n",
       "          1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,\n",
       "         -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,\n",
       "          1., -1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state[:, -3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.0000e-01, -4.0000e-01,  2.0000e-01, -1.0000e+00,  1.6000e+00,\n",
       "         -1.0000e+00, -2.0000e-01,  4.0000e-01, -8.0000e-01,  6.0000e-01],\n",
       "        [ 5.9605e-08, -2.8000e+00,  1.4000e+00,  2.0000e-01, -8.9407e-08,\n",
       "         -2.0000e-01, -1.4000e+00,  8.0000e-01, -1.4901e-08, -1.8000e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state[:, -3] @ new.couplings[-1, :C, :N].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.0000e-01, -4.0000e-01,  2.0000e-01, -1.0000e+00,  1.6000e+00,\n",
       "         -1.0000e+00, -2.0000e-01,  4.0000e-01, -8.0000e-01,  6.0000e-01],\n",
       "        [ 5.9605e-08, -2.8000e+00,  1.4000e+00,  2.0000e-01, -8.9407e-08,\n",
       "         -2.0000e-01, -1.4000e+00,  8.0000e-01, -1.4901e-08, -1.8000e+00]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old.left_field(old_state, x)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.left_couplings[-1, :C, :] == old.W_forth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state[:, -2] @ new.couplings[-1, :, N : 2 * N].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4., -4., -4., -4., -4., -4., -4., -4.,  4., -4.],\n",
       "        [-4.,  4., -4., -4., -4., -4., -4., -4., -4., -4.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state[:, -1] @ new.couplings[-1, :C, 2 * N : 3 * N].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4., -4., -4., -4., -4., -4., -4., -4.,  4., -4.],\n",
       "        [-4.,  4., -4., -4., -4., -4., -4., -4., -4., -4.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old.right_field(old_state, old_readout, y)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relaxation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_final_state, old_final_readout, _ = old.relax(\n",
    "    old_state, old_readout, x, y, 5, ignore_right=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_final_state, _ = new.relax(new_state, 5, ignore_right=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(False))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    torch.all(old_final_state[:, 0, :] == new_final_state[0, 1:-2, :]),\n",
    "    torch.all(old_final_readout == new_final_state[0, -2, :C]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old.perceptron_rule_update(\n",
    "    old_final_state,\n",
    "    old_final_readout,\n",
    "    x,\n",
    "    y,\n",
    "    lr=lr,\n",
    "    threshold=threshold,\n",
    "    weight_decay=weight_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.perceptron_rule(new_final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "torch.all(old.couplings[idx, :, :] == new.couplings[idx, :, N : 2 * N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(new.L):\n",
    "    print(torch.all(new.couplings[idx, :, N : 2 * N] == old.couplings[idx, :, :]))\n",
    "    # print(torch.all(new.couplings[idx, :, :N][non_diagonal_mask] == 0))\n",
    "    # if idx != new.L - 1:\n",
    "    #     new.couplings[idx, :, 2 * N : 3 * N][non_diagonal_mask] = 0\n",
    "print(torch.all(new.couplings[-2, :, 2 * N : 2 * N + C] == old.W_back.T))\n",
    "print(torch.all(new.couplings[-1, :C, :N] == old.W_forth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_logits, _, _ = new.inference(x, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_logits, _, _ = old.inference(x, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
